{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.0-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36064bit27be6fbe43c041f6a1f58b4ba6c110f6",
   "display_name": "Python 3.6.0 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pyltp\n",
    "from snownlp import SnowNLP\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "par_model_path = os.path.join(LTP_DATA_DIR, 'parser.model')  # 分词模型路径， 模型名称为'parser.model'\n",
    "parser = Parser()   # 初始化实例\n",
    "parser.load(par_model_path)   # 加载模型\n",
    "import os\n",
    "# 引入模型文件\n",
    "LTP_DATA_DIR = '/Users/sunhongchao/Documents/craft/Zero-Preprocessing/resources/ltp_data_v3.4.0'  # ltp模型目录的路径\n",
    "\n",
    "cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')  # 分词模型路径，模型名称为`cws.model`\n",
    "pos_model_path = os.path.join(LTP_DATA_DIR, 'pos.model')  # 词性标注模型路径，模型名称为`pos.model`\n",
    "ner_model_path = os.path.join(LTP_DATA_DIR, 'ner.model')  # 命名实体识别模型路径，模型名称为`ner.model`\n",
    "par_model_path = os.path.join(LTP_DATA_DIR, 'parser.model')  # 分词模型路径， 模型名称为'parser.model'\n",
    "\n",
    "\n",
    "#分词\n",
    "from pyltp import Segmentor\n",
    "segmentor = Segmentor()  # 初始化实例\n",
    "segmentor.load(cws_model_path)  # 加载模型\n",
    "\n",
    "#词性标注\n",
    "from pyltp import Postagger\n",
    "postagger = Postagger()  # 初始化实例\n",
    "postagger.load(pos_model_path)  # 加载模型\n",
    "\n",
    "#命名实体识别\n",
    "from pyltp import NamedEntityRecognizer\n",
    "recognizer = NamedEntityRecognizer()  # 初始化实例\n",
    "recognizer.load(ner_model_path)  # 加载模型\n",
    "\n",
    "#句法分析\n",
    "from pyltp import Parser\n",
    "parser = Parser()   # 初始化实例\n",
    "parser.load(par_model_path)   # 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_deal(input_str:str) -> list:\n",
    "    # # 分词/词性标注\n",
    "    # snow_result = SnowNLP(input_str)\n",
    "    # words_list.append(' '.join('%s' % word for (word, tag) in snow_result.tags))\n",
    "    # pos_list.append(' '.join('/%s' % tag for (word, tag) in snow_result.tags))\n",
    "\n",
    "    words = segmentor.segment(jinyong)  # 分词\n",
    "    words_list = list(words)   #words_list列表保存着分词的结果\n",
    "\n",
    "    postags = postagger.postag(words)  # 词性标注\n",
    "    postags_list = list(postags)  #postags_list保存着词性标注的结果\n",
    "\n",
    "    netags = recognizer.recognize(words, postags)  # 命名实体识别\n",
    "    netags_list = list(netags)  #netags_list保存着命名实体识别的结果\n",
    "\n",
    "    # words = ['元芳', '你', '怎么', '看']\n",
    "    # postags = ['nh', 'r', 'r', 'v']\n",
    "    arcs = parser.parse(words, postags)   # 句法分析\n",
    "    print('\\t'.join('%d: %s' %(arc.head, arc.relation) for arc in arcs))\n",
    "\n",
    "    name_list = \n",
    "    loc_list = \n",
    "    org_list = \n",
    "    date_list = \n",
    "\n",
    "    # 关键词\n",
    "    from snownlp import SnowNLP\n",
    "\n",
    "    s = SnowNLP(input_str)\n",
    "    keywords_list = s.keywords(5)\n",
    "\n",
    "    # 长句压缩\n",
    "    if len(input_str) > 20:\n",
    "\n",
    "    \n",
    "    # 信息量衡量\n",
    "\n",
    "    # QQ相似， 找到类似的Q\n",
    "         \n",
    "\n",
    "    return words_list, postags_list, netags_list, keywords_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ltp_release():\n",
    "    segmentor.release()  # 释放模型\n",
    "    postagger.release()  # 释放模型\n",
    "    recognizer.release()  # 释放模型\n",
    "    parser.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def deal_ner():\n",
    "    #去除非命名实体\n",
    "    a = len(words_list)\n",
    "    words_list_1=[]\n",
    "    postags_list_1=[]\n",
    "    netags_list_1=[]\n",
    "    i = 0\n",
    "    while i < a:\n",
    "        if netags_list[i] != 'O':\n",
    "            words_list_1.append(words_list[i])\n",
    "            postags_list_1.append(postags_list[i])\n",
    "            netags_list_1.append(netags_list[i])\n",
    "        i += 1\n",
    "    a1 = len(words_list_1)\n",
    "\n",
    "    #提取人名\n",
    "    i = 0\n",
    "    names=[]\n",
    "    while i<a1:\n",
    "        if netags_list_1[i] == 'S-Nh':\n",
    "            names.append(words_list_1[i])\n",
    "        elif netags_list_1[i] == 'B-Nh':\n",
    "            temp_s3 = ''\n",
    "            temp_s3 += words_list_1[i]\n",
    "            j = i+1\n",
    "            while (j<a1) and (netags_list_1[j]=='I-Nh' or netags_list_1[j]=='E-Nh'):\n",
    "                temp_s3 += words_list_1[j]\n",
    "                j += 1\n",
    "            names.append(temp_s3)\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关键词\n",
    "from snownlp import SnowNLP\n",
    "\n",
    "s = SnowNLP('自然语言处理是计算机科学领域与人工智能领域中的一个重要方向')\n",
    "s_key = s.keywords(5)\n",
    "print(s_key)"
   ]
  }
 ]
}